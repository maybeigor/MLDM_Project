{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-18T10:19:12.927779Z","iopub.status.busy":"2023-11-18T10:19:12.927339Z","iopub.status.idle":"2023-11-18T10:25:08.456317Z","shell.execute_reply":"2023-11-18T10:25:08.454557Z","shell.execute_reply.started":"2023-11-18T10:19:12.927744Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n","The class this function is called from is 'Wav2Vec2Tokenizer'.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231118_102436-x9amghl1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/igorkenzinkz/huggingface/runs/x9amghl1' target=\"_blank\">smart-paper-4</a></strong> to <a href='https://wandb.ai/igorkenzinkz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/igorkenzinkz/huggingface' target=\"_blank\">https://wandb.ai/igorkenzinkz/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/igorkenzinkz/huggingface/runs/x9amghl1' target=\"_blank\">https://wandb.ai/igorkenzinkz/huggingface/runs/x9amghl1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_values,attention_mask,output_attentions,output_hidden_states,return_dict,labels,label,labels,label_ids.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 67\u001b[0m\n\u001b[1;32m     59\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     60\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     61\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     62\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_input_values,\n\u001b[1;32m     63\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mvalidation_input_values\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Запуск обучения\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Сохранение модели\u001b[39;00m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/fine_tuned_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2718\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2700\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2701\u001b[0m \u001b[38;5;124;03mPerform a training step on a batch of inputs.\u001b[39;00m\n\u001b[1;32m   2702\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2715\u001b[0m \u001b[38;5;124;03m    `torch.Tensor`: The tensor with training loss on this batch.\u001b[39;00m\n\u001b[1;32m   2716\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2717\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m-> 2718\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2721\u001b[0m     loss_mb \u001b[38;5;241m=\u001b[39m smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2672\u001b[0m, in \u001b[0;36mTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs)\n\u001b[1;32m   2671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2672\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2673\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe batch received was empty, your model won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be able to train on it. Double-check that your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2674\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining dataset contains keys expected by the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2675\u001b[0m     )\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_past \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2677\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmems\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_past\n","\u001b[0;31mValueError\u001b[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_values,attention_mask,output_attentions,output_hidden_states,return_dict,labels,label,labels,label_ids."]}],"source":["# Импорт необходимых библиотек\n","import pandas as pd\n","import soundfile as sf\n","from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer, Trainer, TrainingArguments\n","import torch\n","import os\n","from sklearn.model_selection import train_test_split\n","!pip install optuna\n","import optuna\n","from optuna.trial import TrialState\n","\n","# Путь к папке с аудиофайлами\n","audio_dir = '/kaggle/input/bengaliai-speech/examples/'\n","\n","# Получение списка аудиофайлов\n","audio_files = [f for f in os.listdir(audio_dir) if f.endswith('.wav')]\n","\n","# Создание DataFrame\n","df = pd.DataFrame({\n","    'audio_path': [os.path.join(audio_dir, file) for file in audio_files]\n","})\n","\n","# Разделение на обучающую и валидационную выборки\n","train_df, validation_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Загрузка предварительно обученной модели и токенизатора\n","model_name = \"ai4bharat/indicwav2vec_v1_bengali\"\n","tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)\n","model = Wav2Vec2ForCTC.from_pretrained(model_name)\n","\n","# Функция для чтения аудиофайла\n","def read_audio(file_path):\n","    speech, _ = sf.read(file_path)\n","    return speech\n","\n","# Функция для подготовки данных\n","def prepare_data(df):\n","    input_values = []\n","    for _, row in df.iterrows():\n","        speech = read_audio(row['audio_path'])\n","        input_value = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values[0]\n","        input_values.append(input_value)\n","\n","    return torch.stack(input_values)\n","\n","# Подготовка данных\n","train_input_values = prepare_data(train_df)\n","validation_input_values = prepare_data(validation_df)\n","\n","# Настройки обучения\n","training_args = TrainingArguments(\n","  output_dir=\"/kaggle/working/results\",\n","  per_device_train_batch_size=16,\n","  evaluation_strategy=\"steps\",\n","  num_train_epochs=1,\n","  save_steps=400,\n","  eval_steps=400,\n","  logging_steps=400\n",")\n","\n","# Создание Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_input_values,\n","    eval_dataset=validation_input_values\n",")\n","\n","# Запуск обучения\n","trainer.train()\n","\n","# Сохранение модели\n","model.save_pretrained(\"/kaggle/working/fine_tuned_model\")\n","\n","best_params = {\"beam_width\": 768}\n","\n","if FIND_PARAMS:\n","\n","    valid = pd.read_csv(DATA / \"train.csv\") # dtype={\"id\": str}\n","    valid = valid.query('split==\"valid\"').sample(n=10000, random_state=42).reset_index(drop=True)\n","    valid_audio_paths = [str(TRAIN / f\"{aid}.mp3\") for aid in valid[\"id\"].values]\n","\n","    valid_dataset = BengaliSRTestDataset(\n","        valid_audio_paths, SAMPLING_RATE\n","    )\n","\n","    collate_func = partial(\n","        processor_with_lm.feature_extractor,\n","        return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n","        padding=True,\n","    )\n","\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=8, shuffle=False,\n","        num_workers=2, collate_fn=collate_func, drop_last=False,\n","        pin_memory=True,\n","    )\n","    # Calculating the base score\n","    print(constants)\n","    logits = inference(model, valid_loader)\n","    base_preds = decode(logits)\n","    gts = valid[\"sentence\"].values.tolist()\n","    base_wer_score = score(gts, base_preds)\n","    print(f\"Base wer score: {base_wer_score}\")\n","\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective, n_trials=25)\n","\n","    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n","    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n","\n","    print(\"Study statistics: \")\n","    print(\"  Number of finished trials: \", len(study.trials))\n","    print(\"  Number of pruned trials: \", len(pruned_trials))\n","    print(\"  Number of complete trials: \", len(complete_trials))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: \", trial.value)\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","\n","    if study.best_value < base_wer_score:\n","        print(f\"Base score improved to {study.best_value} from {base_wer_score}. Assigning {study.best_params} to best_params\")\n","        best_params = study.best_params\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_params = {'alpha': 0.3802723523729998, 'beta': 0.053996879617918436, 'beam_width': 768}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Running the inference with params: {best_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n","test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n","\n","test_dataset = BengaliSRTestDataset(\n","    test_audio_paths, SAMPLING_RATE\n",")\n","collate_func = partial(\n","    processor_with_lm.feature_extractor,\n","    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n","    padding=True,\n",")\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=8, shuffle=False,\n","    num_workers=2, collate_fn=collate_func, drop_last=False,\n","    pin_memory=True,\n",")\n","\n","pred_sentence_list = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(test_loader):\n","        x = batch[\"input_values\"]\n","        x = x.to(device, non_blocking=True)\n","        with torch.cuda.amp.autocast(True):\n","            y = model(x).logits\n","        y = y.detach().cpu().numpy()\n","\n","        for l in y:\n","            sentence = processor_with_lm.decode(l, **best_params).text\n","            pred_sentence_list.append(sentence)\n","\n","\n","pp_pred_sentence_list = [postprocess(s) for s in tqdm(pred_sentence_list)]"]},{"cell_type":"markdown","metadata":{},"source":["# SUBMITION"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test[\"sentence\"] = pp_pred_sentence_list\n","test.to_csv(\"submission.csv\", index=False)\n","print(test.head())"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":6229904,"sourceId":52324,"sourceType":"competition"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
